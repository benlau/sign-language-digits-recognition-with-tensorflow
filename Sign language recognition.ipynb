{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign language digits recognition with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Libraries to manage the dataset\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "\n",
    "# Deep leearnig and machine learning libraries (Keras and scikit learn)\n",
    "from os import listdir\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Classic libraries with python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data\"></a>\n",
    "## A look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings:\n",
    "img_size = 64\n",
    "num_class = 10\n",
    "\n",
    "def get_img(data_path):\n",
    "    # Getting image array from path:\n",
    "    img = cv2.imread(data_path, 0)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    return img\n",
    "\n",
    "def get_dataset(dataset_path='dataset'):\n",
    "    labels = listdir(dataset_path) # Geting labels\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i, label in enumerate(labels):\n",
    "        datas_path = dataset_path+'/'+label\n",
    "        for data in listdir(datas_path):\n",
    "            img = get_img(datas_path+'/'+data)\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "    # Create dateset:\n",
    "    X = np.array(X).astype('float32')\n",
    "    # Normalized the input\n",
    "    X = (X - np.mean(X))/np.std(X)\n",
    "    Y = np.array(Y).astype('float32')\n",
    "    # Categorize the output into binary class matrix\n",
    "    Y = tf.keras.utils.to_categorical(Y, num_class)\n",
    "    return X, Y\n",
    "\n",
    "X,Y = get_dataset()\n",
    "# add another axis representing grey-scale\n",
    "X_axis = X[:,:,:,np.newaxis]\n",
    "\n",
    "# Split the test set and validatio set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_axis, Y, test_size = 0.2 , random_state = 42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2 , random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images = 2062\n",
      "number of training examples = 1319\n",
      "number of test examples = 413\n",
      "number of test examples = 330\n",
      "X_train shape: (1319, 64, 64, 1)\n",
      "Y_train shape: (1319, 10)\n",
      "X_test shape: (413, 64, 64, 1)\n",
      "Y_test shape: (413, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"Total number of images = \" + str(X.shape[0]))\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neuralNet'></a>\n",
    "\n",
    "## Model 1: Create our ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1319 samples, validate on 330 samples\n",
      "Epoch 1/30\n",
      "1319/1319 [==============================] - 3s 2ms/step - loss: 2.0947 - acc: 0.3768 - val_loss: 1.0679 - val_acc: 0.6485\n",
      "Epoch 2/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 1.0400 - acc: 0.6399 - val_loss: 0.8045 - val_acc: 0.7455\n",
      "Epoch 3/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.7107 - acc: 0.7453 - val_loss: 0.8689 - val_acc: 0.7485\n",
      "Epoch 4/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.6252 - acc: 0.7885 - val_loss: 0.7552 - val_acc: 0.7485\n",
      "Epoch 5/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.5454 - acc: 0.8165 - val_loss: 0.7389 - val_acc: 0.7788\n",
      "Epoch 6/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.4392 - acc: 0.8506 - val_loss: 0.7360 - val_acc: 0.7697\n",
      "Epoch 7/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.3558 - acc: 0.8704 - val_loss: 0.6454 - val_acc: 0.7879\n",
      "Epoch 8/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.3304 - acc: 0.8802 - val_loss: 0.6848 - val_acc: 0.8091\n",
      "Epoch 9/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.2721 - acc: 0.9060 - val_loss: 0.7039 - val_acc: 0.8000\n",
      "Epoch 10/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.2364 - acc: 0.9204 - val_loss: 0.7125 - val_acc: 0.8242\n",
      "Epoch 11/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.2266 - acc: 0.9249 - val_loss: 0.5074 - val_acc: 0.8485\n",
      "Epoch 12/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.2365 - acc: 0.9189 - val_loss: 0.6688 - val_acc: 0.8364\n",
      "Epoch 13/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1887 - acc: 0.9356 - val_loss: 0.5867 - val_acc: 0.8273\n",
      "Epoch 14/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.1571 - acc: 0.9484 - val_loss: 0.6438 - val_acc: 0.8152\n",
      "Epoch 15/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1729 - acc: 0.9378 - val_loss: 0.6227 - val_acc: 0.8333\n",
      "Epoch 16/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.1251 - acc: 0.9515 - val_loss: 0.6452 - val_acc: 0.8333\n",
      "Epoch 17/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1578 - acc: 0.9484 - val_loss: 0.7576 - val_acc: 0.8091\n",
      "Epoch 18/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1438 - acc: 0.9530 - val_loss: 0.7266 - val_acc: 0.8061\n",
      "Epoch 19/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1008 - acc: 0.9613 - val_loss: 0.6956 - val_acc: 0.8576\n",
      "Epoch 20/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1312 - acc: 0.9568 - val_loss: 0.7995 - val_acc: 0.8152\n",
      "Epoch 21/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.0925 - acc: 0.9659 - val_loss: 0.7232 - val_acc: 0.8364\n",
      "Epoch 22/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.0885 - acc: 0.9704 - val_loss: 0.8333 - val_acc: 0.8152\n",
      "Epoch 23/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1166 - acc: 0.9568 - val_loss: 0.7618 - val_acc: 0.8182\n",
      "Epoch 24/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1138 - acc: 0.9613 - val_loss: 1.0400 - val_acc: 0.8061\n",
      "Epoch 25/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1202 - acc: 0.9598 - val_loss: 0.8517 - val_acc: 0.8182\n",
      "Epoch 26/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1567 - acc: 0.9545 - val_loss: 0.7724 - val_acc: 0.8242\n",
      "Epoch 27/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1553 - acc: 0.9492 - val_loss: 0.7319 - val_acc: 0.8273\n",
      "Epoch 28/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1269 - acc: 0.9568 - val_loss: 0.7791 - val_acc: 0.8364\n",
      "Epoch 29/30\n",
      "1319/1319 [==============================] - 2s 1ms/step - loss: 0.1243 - acc: 0.9583 - val_loss: 0.7251 - val_acc: 0.8212\n",
      "Epoch 30/30\n",
      "1319/1319 [==============================] - 2s 2ms/step - loss: 0.0773 - acc: 0.9735 - val_loss: 0.7625 - val_acc: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14306cfd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/model1\")\n",
    "model1.fit(X_train, Y_train, batch_size=32, validation_data=[X_val, Y_val], epochs=30, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='runTheModel'></a>\n",
    "\n",
    "## Evaluate the result of Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,263,178\n",
      "Trainable params: 2,263,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "413/413 [==============================] - 0s 178us/step\n",
      "Loss: 1.1721  Accuaracy: 0.7482%\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "score = model1.evaluate(X_test, Y_test)\n",
    "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CNNModel'></a>\n",
    "\n",
    "## Model 2: Create our CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1319 samples, validate on 330 samples\n",
      "Epoch 1/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 1.2185 - acc: 0.5898 - val_loss: 1.2614 - val_acc: 0.5242\n",
      "Epoch 2/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.4809 - acc: 0.8431 - val_loss: 0.7100 - val_acc: 0.7970\n",
      "Epoch 3/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.2844 - acc: 0.9128 - val_loss: 0.5500 - val_acc: 0.8727\n",
      "Epoch 4/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.1912 - acc: 0.9500 - val_loss: 0.3674 - val_acc: 0.9182\n",
      "Epoch 5/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.1360 - acc: 0.9629 - val_loss: 0.3014 - val_acc: 0.9242\n",
      "Epoch 6/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.1026 - acc: 0.9742 - val_loss: 0.2734 - val_acc: 0.9333\n",
      "Epoch 7/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0823 - acc: 0.9773 - val_loss: 0.2518 - val_acc: 0.9333\n",
      "Epoch 8/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0738 - acc: 0.9818 - val_loss: 0.2085 - val_acc: 0.9273\n",
      "Epoch 9/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0625 - acc: 0.9879 - val_loss: 0.1650 - val_acc: 0.9485\n",
      "Epoch 10/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0423 - acc: 0.9924 - val_loss: 0.1446 - val_acc: 0.9576\n",
      "Epoch 11/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0381 - acc: 0.9901 - val_loss: 0.1559 - val_acc: 0.9545\n",
      "Epoch 12/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0275 - acc: 0.9962 - val_loss: 0.1388 - val_acc: 0.9576\n",
      "Epoch 13/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0548 - acc: 0.9856 - val_loss: 0.2681 - val_acc: 0.9061\n",
      "Epoch 14/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0348 - acc: 0.9939 - val_loss: 0.1708 - val_acc: 0.9515\n",
      "Epoch 15/30\n",
      "1319/1319 [==============================] - 5s 3ms/step - loss: 0.0306 - acc: 0.9932 - val_loss: 0.1778 - val_acc: 0.9515\n",
      "Epoch 16/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0162 - acc: 0.9985 - val_loss: 0.1429 - val_acc: 0.9576\n",
      "Epoch 17/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0154 - acc: 0.9962 - val_loss: 0.1395 - val_acc: 0.9485\n",
      "Epoch 18/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0133 - acc: 0.9985 - val_loss: 0.1054 - val_acc: 0.9727\n",
      "Epoch 19/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0095 - acc: 0.9992 - val_loss: 0.1041 - val_acc: 0.9667\n",
      "Epoch 20/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0320 - acc: 0.9932 - val_loss: 0.1317 - val_acc: 0.9515\n",
      "Epoch 21/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0663 - acc: 0.9757 - val_loss: 0.1729 - val_acc: 0.9455\n",
      "Epoch 22/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0358 - acc: 0.9901 - val_loss: 0.1507 - val_acc: 0.9515\n",
      "Epoch 23/30\n",
      "1319/1319 [==============================] - 5s 3ms/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.1292 - val_acc: 0.9636\n",
      "Epoch 24/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0496 - acc: 0.9848 - val_loss: 0.2104 - val_acc: 0.9273\n",
      "Epoch 25/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0387 - acc: 0.9886 - val_loss: 0.1726 - val_acc: 0.9576\n",
      "Epoch 26/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0224 - acc: 0.9947 - val_loss: 0.1108 - val_acc: 0.9545\n",
      "Epoch 27/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0147 - acc: 0.9962 - val_loss: 0.0946 - val_acc: 0.9636\n",
      "Epoch 28/30\n",
      "1319/1319 [==============================] - 4s 3ms/step - loss: 0.0262 - acc: 0.9939 - val_loss: 0.1086 - val_acc: 0.9667\n",
      "Epoch 29/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0260 - acc: 0.9947 - val_loss: 0.1213 - val_acc: 0.9667\n",
      "Epoch 30/30\n",
      "1319/1319 [==============================] - 5s 4ms/step - loss: 0.0171 - acc: 0.9970 - val_loss: 0.1468 - val_acc: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a303518>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build our CNN\n",
    "model2 = tf.keras.models.Sequential()\n",
    "# Convolutional Blocks: (1) Convolution, (2) Activation, (3) Pooling\n",
    "model2.add(tf.keras.layers.Conv2D(input_shape=(64, 64, 1), filters=64, kernel_size=(4,4), strides=(2)))\n",
    "model2.add(tf.keras.layers.Activation('relu'))\n",
    "model2.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#outputs a (20, 20, 32) matrix\n",
    "model2.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1)))\n",
    "model2.add(tf.keras.layers.Activation('relu'))\n",
    "#outputs a (8, 8, 32) matrix\n",
    "model2.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# dropout helps with over fitting by randomly dropping nodes each epoch\n",
    "model2.add(tf.keras.layers.Dropout(0.3))\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/model2\")\n",
    "model2.fit(X_train, Y_train, batch_size=32, validation_data=[X_val, Y_val], epochs=30, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='runTheModel'></a>\n",
    "\n",
    "## Evaluate the result of Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 31, 31, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 660,362\n",
      "Trainable params: 659,850\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Loss: 0.2562  Accuaracy: 0.9419%\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Result is  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] , Answer is  [0]\n",
      "Predicted Result from Neural net: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] , Predicted Answer is  [0]\n",
      "Predicted Result from CNN: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] , Predicted Answer is  [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x147cb2e80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testNum = 182\n",
    "test_image = X_axis[testNum]\n",
    "plt.imshow(test_image[:,:,0])\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result1 = model1.predict(test_image)\n",
    "result2 = model2.predict(test_image)\n",
    "# For external image\n",
    "#test_img = get_img('./test.jpg')\n",
    "# plt.imshow(test_img)\n",
    "#test_img = np.expand_dims(test_img, axis = 0)\n",
    "# test_img = test_img[:,:,:,np.newaxis]\n",
    "result1 = model1.predict(test_image)\n",
    "result2 = model2.predict(test_image)\n",
    "result1_val = [i for i, j in enumerate(np.round(result1,1)[0]) if j == max(np.round(result1,1)[0])]\n",
    "result2_val = [i for i, j in enumerate(np.round(result2,1)[0]) if j == max(np.round(result2,1)[0])]\n",
    "print('Correct Result is ',Y[testNum], ', Answer is ',[i for i, j in enumerate(Y[testNum]) if j == max(Y[testNum])])\n",
    "print('Predicted Result from Neural net:',   np.round(result1,1)[0], ', Predicted Answer is ',result1_val)\n",
    "print('Predicted Result from CNN:', np.round(result2,1)[0], ', Predicted Answer is ',result2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: CNN Model with Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 9s 206ms/step - loss: 2.0716 - acc: 0.3204 - val_loss: 1.7521 - val_acc: 0.3636\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 4s 107ms/step - loss: 1.3523 - acc: 0.5285 - val_loss: 0.8932 - val_acc: 0.7727\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 5s 111ms/step - loss: 1.0075 - acc: 0.6550 - val_loss: 0.6805 - val_acc: 0.8939\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 5s 114ms/step - loss: 0.7426 - acc: 0.7350 - val_loss: 0.4834 - val_acc: 0.9152\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 7s 159ms/step - loss: 0.6564 - acc: 0.7879 - val_loss: 0.4663 - val_acc: 0.8818\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 6s 140ms/step - loss: 0.6061 - acc: 0.8009 - val_loss: 0.2892 - val_acc: 0.9455\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 7s 161ms/step - loss: 0.5525 - acc: 0.8102 - val_loss: 0.2556 - val_acc: 0.9273\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 4s 102ms/step - loss: 0.4569 - acc: 0.8515 - val_loss: 0.2008 - val_acc: 0.9455\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.4137 - acc: 0.8627 - val_loss: 0.1743 - val_acc: 0.9545\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.4401 - acc: 0.8608 - val_loss: 0.1498 - val_acc: 0.9667\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 4s 94ms/step - loss: 0.3476 - acc: 0.8984 - val_loss: 0.1273 - val_acc: 0.9667\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 0.3157 - acc: 0.8902 - val_loss: 0.1287 - val_acc: 0.9636\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 5s 110ms/step - loss: 0.3341 - acc: 0.8891 - val_loss: 0.0990 - val_acc: 0.9788\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 118ms/step - loss: 0.3027 - acc: 0.8962 - val_loss: 0.0984 - val_acc: 0.9636\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 5s 120ms/step - loss: 0.2925 - acc: 0.9077 - val_loss: 0.0940 - val_acc: 0.9758\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 0.2965 - acc: 0.8921 - val_loss: 0.0861 - val_acc: 0.9788\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 4s 94ms/step - loss: 0.2887 - acc: 0.9073 - val_loss: 0.0598 - val_acc: 0.9879\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 4s 95ms/step - loss: 0.2294 - acc: 0.9256 - val_loss: 0.1050 - val_acc: 0.9727\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 5s 129ms/step - loss: 0.2303 - acc: 0.9245 - val_loss: 0.0773 - val_acc: 0.9818\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 4s 104ms/step - loss: 0.2420 - acc: 0.9207 - val_loss: 0.0771 - val_acc: 0.9879\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 0.2043 - acc: 0.9442 - val_loss: 0.1551 - val_acc: 0.9576\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 0.2142 - acc: 0.9323 - val_loss: 0.0739 - val_acc: 0.9818\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 4s 103ms/step - loss: 0.1939 - acc: 0.9319 - val_loss: 0.0631 - val_acc: 0.9788\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 5s 127ms/step - loss: 0.1574 - acc: 0.9568 - val_loss: 0.0413 - val_acc: 0.9939\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 0.1761 - acc: 0.9457 - val_loss: 0.0417 - val_acc: 0.9909\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 0.1625 - acc: 0.9457 - val_loss: 0.0448 - val_acc: 0.9909\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 0.1956 - acc: 0.9315 - val_loss: 0.0428 - val_acc: 0.9939\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.1839 - acc: 0.9401 - val_loss: 0.0272 - val_acc: 0.9939\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 7s 175ms/step - loss: 0.1603 - acc: 0.9483 - val_loss: 0.0259 - val_acc: 0.9970\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 0.1566 - acc: 0.9486 - val_loss: 0.0357 - val_acc: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147579518>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a more diverse dataset by rotating, shifting and zooming the image\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=16,\n",
    "    width_shift_range=0.12,\n",
    "    height_shift_range=0.12,\n",
    "    zoom_range=0.12\n",
    "    )\n",
    "   \n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "# Model3: Add Image Generate\n",
    "# build our CNN\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "# Convolutional Blocks: (1) Convolution, (2) Activation, (3) Pooling\n",
    "model3.add(tf.keras.layers.Conv2D(input_shape=(64, 64, 1), filters=64, kernel_size=(4,4), strides=(2)))\n",
    "model3.add(tf.keras.layers.Activation('relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#outputs a (20, 20, 32) matrix\n",
    "model3.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1)))\n",
    "model3.add(tf.keras.layers.Activation('relu'))\n",
    "#outputs a (8, 8, 32) matrix\n",
    "model3.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# dropout helps with over fitting by randomly dropping nodes each epoch\n",
    "model3.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/model2\")\n",
    "model3.fit_generator(datagen.flow(X_train, Y_train, batch_size=32), validation_data=(X_val, Y_val), epochs=30, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the result of Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 31, 31, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 660,362\n",
      "Trainable params: 659,850\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Loss: 0.0711  Accuaracy: 0.9782%\n"
     ]
    }
   ],
   "source": [
    "model3.summary()\n",
    "score = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay ! We clearly see an improvement ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
